{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOYf9QDDH/ALQw8bQMAmHkT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Feature Extraction from Dicts\n","Representing large dataset using a dense matrix may require huge memory and compute time. For example, representing a dataset with 1 millon samples and 1 millon features using a dense matrix requires order of $10^{12}$ byte or 1 TB memory. And a dataset having 1 million samples and 1 million features is not uncommon in real life. However, most of those datasets has sparse features and thus, can be represented in more efficiently. For example, consider a dataset with the following feature matrix.\n","\n","|  | f1 | f2 | f3 | f5 | f6 | f7 | f8 |\n","---|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n","s1 | 0  | 0.5|  0 | 0  | 2.3| 0  | 0  |\n","s2 | 1.9| 0  |  0 | 0  | 0  | 0  | 2.1|\n","s3 | 0  | 0  | 0.9| 1.3| 0  | 0  | 1.1|\n","s4 | 0  | 0  |  0 | 0  | 0.1| 3.1| 0  |\n","s5 | 1.9| 0  |  0 | 0  | 0  | 0  | 0  |\n","\n","In the above dataset, most of the entries in the feature matrix are zero. Thus, it is more efficient to store the features as a sparse matrix and perform the machine learning operations on the sparse matrix. The scipy package [scipy.sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html) defines several matrix and array classes for different sparse matrix formats. You can represents your data as a sparse matrix to work with the Scikit-learn's machine learning algorithms.\n","\n","Sometimes representing a dataset with sparse features using python dictionaries can be more convenient. You can represent the above dataset as a list of python dictionaries as follows:\n","\n","| sample | Features |\n",":-------:|:-------- |\n","s1       | {'f2': 0.5, 'f6': 2.3} |\n","s2       | {'f1': 1.9, 'f8': 2.1} |\n","s3       | {'f3': 0.9, 'f4': 1.3, 'f8': 1.1} |\n","s4       | {'f6': 0.1, 'f7': 3.1} |\n","s5       | {'f1': 1.9, 'f6': 2.3} |\n","\n","Scikit-learn provides a class <em>sklearn.feature_extraction.DictVectorizer</em> to convert the list of python dictionaries into a numpy array or scipy.sparse matrix. The full documentation of <em>sklearn.feature_extraction.DictVectorizer</em> can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html)."],"metadata":{"id":"HZzKHOtJaTSq"}},{"cell_type":"markdown","source":["## Working with Scikit-learn DictVectorizer\n","The original code can be found [here](https://scikit-learn.org/stable/modules/feature_extraction.html)."],"metadata":{"id":"uJC4VBD3dXCy"}},{"cell_type":"markdown","source":["### Creating a small dataset"],"metadata":{"id":"uboAaC3aziIP"}},{"cell_type":"code","source":["measurements = [\n","     {'city': 'Dubai', 'temperature': 33.},\n","     {'city': 'London', 'temperature': 12.},\n","     {'city': 'San Francisco', 'temperature': 18.},\n"," ]"],"metadata":{"id":"XoaRvI9ZzmDR","executionInfo":{"status":"ok","timestamp":1697461514652,"user_tz":-330,"elapsed":4,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Importing the DictVectorizer"],"metadata":{"id":"V-pQ10LCzr8-"}},{"cell_type":"code","source":["from sklearn.feature_extraction import DictVectorizer"],"metadata":{"id":"LylpK-dzzwid","executionInfo":{"status":"ok","timestamp":1697461520351,"user_tz":-330,"elapsed":3,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Transforming the data"],"metadata":{"id":"7dIOich_z4lx"}},{"cell_type":"code","source":["vec = DictVectorizer(sparse=True)\n","\n","vec.fit(measurements)\n","X = vec.transform(measurements)\n","\n","# Alternatively, you can call fit_tranform() to call both fit() and transform() together\n","# X = vec.fit_transform(measurements)"],"metadata":{"id":"Bkbe4Tzgz3t2","executionInfo":{"status":"ok","timestamp":1697461603118,"user_tz":-330,"elapsed":444,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["type(X)"],"metadata":{"id":"v2yMHa7i1PCU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697461605647,"user_tz":-330,"elapsed":7,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"cd80bbe7-3fe6-4cdf-c806-983f9ecd073a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["scipy.sparse._csr.csr_matrix"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["X"],"metadata":{"id":"zRKLvytztR8q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697461609203,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"d84d030a-cf83-411f-db02-af1e0e80c857"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<3x4 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 6 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["X.toarray()"],"metadata":{"id":"bFgDT8Si1UsE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697461637330,"user_tz":-330,"elapsed":438,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"8e22d149-e8cb-4998-cd3f-964a39c8918f"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.,  0.,  0., 33.],\n","       [ 0.,  1.,  0., 12.],\n","       [ 0.,  0.,  1., 18.]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### Viewing the feature names"],"metadata":{"id":"7Y30HCDQ24yw"}},{"cell_type":"code","source":["vec.get_feature_names_out()"],"metadata":{"id":"_dmixXIqdi1Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697461664675,"user_tz":-330,"elapsed":459,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"750aa3a4-edcb-40bb-bbeb-a15dc1778ce5"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['city=Dubai', 'city=London', 'city=San Francisco', 'temperature'],\n","      dtype=object)"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Another Example"],"metadata":{"id":"kKZHzTZN3Dew"}},{"cell_type":"markdown","source":["### The dataset"],"metadata":{"id":"jiJVY8K23LQ0"}},{"cell_type":"code","source":["movie_entry = [{'category': ['thriller', 'drama'], 'year': 2003},\n","               {'category': ['animation', 'family'], 'year': 2011},\n","               {'year': 1974}]"],"metadata":{"id":"bD4SxO0F3PmK","executionInfo":{"status":"ok","timestamp":1697461747949,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### Transforming dataset"],"metadata":{"id":"QhxBfUQm3TO-"}},{"cell_type":"code","source":["X = vec.fit_transform(movie_entry)\n","print(vec.get_feature_names_out())"],"metadata":{"id":"aCzQJTw43WPV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697461753525,"user_tz":-330,"elapsed":460,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"cb61a7aa-0bc1-4030-efa8-0d84ac7d9e8b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["['category=animation' 'category=drama' 'category=family'\n"," 'category=thriller' 'year']\n"]}]},{"cell_type":"code","source":["X.toarray()"],"metadata":{"id":"n2ehySvI35s9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697461784627,"user_tz":-330,"elapsed":562,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"8e2a0bd2-da5e-47ee-d3b0-c0d420385a85"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 2.003e+03],\n","       [1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 2.011e+03],\n","       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.974e+03]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### What happens to unseen features?"],"metadata":{"id":"YAknMLHx3jWy"}},{"cell_type":"code","source":["vec.transform({'category': ['thriller'],\n","               'unseen_feature': '3'}).toarray()"],"metadata":{"id":"kU81jg8afF_s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697462154400,"user_tz":-330,"elapsed":421,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"af3df5bd-12b0-4607-a804-225494a8c671"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 1., 0.]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Feature Extraction from Raw Text\n","In many real life machine learning problems, the raw texts are used as the input to the system. For example, in a news article classification task which classifies a news article into different categories like political, sports-related, business-related etc., the input to the task is a news article. However, machine learning algorithms cannot operate on raw texts. To work with such textual data, many preprocessing steps are performed to convert the data into some stardard formats like vectors of real numbers. Common preprocessing pipelines involve steps like\n","* Tokenization\n","* Lower casing\n","* Stemming\n","* Lemmatization\n","* Stop word removal\n","* Vectorization\n","\n","In this tutorial, we will first go through some of the examples of those steps using [NLTK library](https://www.nltk.org/). Then we will see how those steps can be perform using Scikit-learn [Features Extraction](https://scikit-learn.org/stable/modules/feature_extraction.html) module."],"metadata":{"id":"RxoxlkY-gr7c"}},{"cell_type":"markdown","source":["## Text Preprocessing Pipeline\n","Please refer to [this blog](https://medium.com/mlearning-ai/nlp-tokenization-stemming-lemmatization-and-part-of-speech-tagging-9088ac068768) for a better understanding."],"metadata":{"id":"C2yxPlJT7m8g"}},{"cell_type":"markdown","source":["### Tokenization"],"metadata":{"id":"bYfQ0hdq7_JG"}},{"cell_type":"code","source":["import nltk\n","from nltk import sent_tokenize\n","from nltk import word_tokenize\n","nltk.download('punkt')"],"metadata":{"id":"PdX2IpaT8DN8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697462711066,"user_tz":-330,"elapsed":1184,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"2ede23ae-b056-4315-ccb3-72c13401e2f0"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["text = \"Hello everyone! Welcome to my blog post on Medium. We are studying Natural Language Processing.\""],"metadata":{"id":"dFCwuoNz8wAt","executionInfo":{"status":"ok","timestamp":1697462782344,"user_tz":-330,"elapsed":17,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Sentence tokenization"],"metadata":{"id":"g9zL862j85OC"}},{"cell_type":"code","source":["tokens_sents = nltk.sent_tokenize(text)\n","print(tokens_sents)"],"metadata":{"id":"tJaU9hMh8w7y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697462789707,"user_tz":-330,"elapsed":19,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"f2c7d9e7-bdfa-49a7-b622-d9b91f57e320"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello everyone!', 'Welcome to my blog post on Medium.', 'We are studying Natural Language Processing.']\n"]}]},{"cell_type":"markdown","source":["Word tokenization"],"metadata":{"id":"MwIFNl3j9AtC"}},{"cell_type":"code","source":["tokens_words = nltk.word_tokenize(text)\n","print(tokens_words)"],"metadata":{"id":"OQAL6XNN9EKj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697462811679,"user_tz":-330,"elapsed":456,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"57466941-284c-4603-8b81-31ea63c74f15"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello', 'everyone', '!', 'Welcome', 'to', 'my', 'blog', 'post', 'on', 'Medium', '.', 'We', 'are', 'studying', 'Natural', 'Language', 'Processing', '.']\n"]}]},{"cell_type":"markdown","source":["### Lower casing"],"metadata":{"id":"4i0ngKcF8KEU"}},{"cell_type":"code","source":["token_words_lowercased = [w.lower() for w in tokens_words]\n","print(token_words_lowercased)"],"metadata":{"id":"bhActCIT-Kkq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697463371233,"user_tz":-330,"elapsed":437,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"5802eaff-81b0-4bb6-8070-18336fa1ae74"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['hello', 'everyone', '!', 'welcome', 'to', 'my', 'blog', 'post', 'on', 'medium', '.', 'we', 'are', 'studying', 'natural', 'language', 'processing', '.']\n"]}]},{"cell_type":"markdown","source":["### Stemming"],"metadata":{"id":"eMuH1v4t-lSR"}},{"cell_type":"code","source":["from nltk.stem import PorterStemmer"],"metadata":{"id":"C4lK3WW0-nfM","executionInfo":{"status":"ok","timestamp":1697463480977,"user_tz":-330,"elapsed":419,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["ps = PorterStemmer()\n","words = [\"civilization\", \"boy's\", \"boyes\", \"boy\"]\n","print([ps.stem(w) for w in words])"],"metadata":{"id":"QNotDUfc-5EV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697463483498,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"78b7244d-74cf-45c2-a20d-6a261cc36e03"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["['civil', \"boy'\", 'boy', 'boy']\n"]}]},{"cell_type":"markdown","source":["### Lemmatization"],"metadata":{"id":"tBK_BF2JAinX"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"metadata":{"id":"b-Foe1cwAlUR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697463622908,"user_tz":-330,"elapsed":442,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"7608d082-ea42-476c-e5ee-b0c680cc9c5a"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["text = \"The striped bats are hanging on their feet for best\"\n","words = nltk.word_tokenize(text)"],"metadata":{"id":"gKr0yHgfAnJr","executionInfo":{"status":"ok","timestamp":1697463626436,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["words"],"metadata":{"id":"rsA24lHOF_i5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697463631353,"user_tz":-330,"elapsed":428,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"e949e050-5bf8-4c34-c329-d89e4b49f693"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The',\n"," 'striped',\n"," 'bats',\n"," 'are',\n"," 'hanging',\n"," 'on',\n"," 'their',\n"," 'feet',\n"," 'for',\n"," 'best']"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["print([ps.stem(w) for w in words])"],"metadata":{"id":"IQG1Jm6xCesB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697463648591,"user_tz":-330,"elapsed":463,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"b3572dbe-489b-476d-be2b-b3844e02094d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'stripe', 'bat', 'are', 'hang', 'on', 'their', 'feet', 'for', 'best']\n"]}]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","print([lemmatizer.lemmatize(w) for w in words])"],"metadata":{"id":"8JJwCaHDCgN3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697463655973,"user_tz":-330,"elapsed":1566,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"1683fb6c-443d-430c-c0ad-28fd9a7b24e3"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'striped', 'bat', 'are', 'hanging', 'on', 'their', 'foot', 'for', 'best']\n"]}]},{"cell_type":"markdown","source":["### Stop words removal"],"metadata":{"id":"DyIl6pnmC_WC"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')"],"metadata":{"id":"xKrUeRGtGTYs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697463824121,"user_tz":-330,"elapsed":451,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"fd19c082-3ed0-4aad-e012-c63bd3e09cf1"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["sw = stopwords.words('english')\n","print(len(sw))\n","print(sw[:10])\n","print(sw[-10:])"],"metadata":{"id":"VrphKyTrDCl4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697463846563,"user_tz":-330,"elapsed":436,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"640030c5-715c-4d20-d1e1-1a64c7a1e38d"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["179\n","['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n","['shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"]}]},{"cell_type":"code","source":["print(words)"],"metadata":{"id":"vd4scSV5G0o0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697464004192,"user_tz":-330,"elapsed":436,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"728e329c-e0a4-4e98-d054-2432e8796bcf"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n"]}]},{"cell_type":"code","source":["words_stopwords_removed = [w for w in words if w.lower() not in sw]\n","print(words_stopwords_removed)"],"metadata":{"id":"g9aWXbM5G3x0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697464242329,"user_tz":-330,"elapsed":442,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"9393ca4a-aeef-481f-b11a-313dab42afd3"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["['striped', 'bats', 'hanging', 'feet', 'best']\n"]}]},{"cell_type":"markdown","source":["### Vectorization\n","Vectorization is the process of representing the list of words obtained after all the previous preprocessing (i.e. tokenization, stopwords removal, stemming, lemmatization etc.). Consider the following example of analysis review comments:\n","\n","**Review 1**: Game of Thrones is an amazing tv series!\n","\n","**Review 2**: Game of Thrones is the best tv series!\n","\n","**Review 3**: Game of Thrones is so great\n","\n","A possible vectorization for the above dataset can be\n","\n","\n","|   | amazing | an  | best | game | great | is | of | series | so | the | thrones | tv\n","|:--|:-------:|:---:|:----:|:----:|:-----:|:--:|:--:|:------:|:--:|:---:|:------:|:---:\n","| **0** | 1       | 1   | 0    | 1    | 0     | 1  | 1  | 1      | 0  | 0   | 1       | 1\n","| **1** | 0       | 0   | 1    | 1    | 0     | 1  | 1  | 1      | 0  | 1   |1       | 1\n","| **2** | 0 | 0   | 0   | 1    | 1    | 1     | 1  | 0  | 1      | 0  | 1   |  0       |\n","\n","The above feature representation is called <em>Bag of Words</em> representation."],"metadata":{"id":"D9DXpjWUIFMY"}},{"cell_type":"markdown","source":["## Bag of Word Representation\n","Scikit-learn provides the class <em>sklearn.feature_extraction.text.CountVectorizer</em> to convert a list of raw texts into a sparse matrix of bag-of-words features. The class internally performs the neccessary preprocessing steps like tokenization, lower casing, stopwords removal etc. and returns the bag-of-words representation. The stemming and lemmatization, though tricky, can also be added into the pipeline if needed. The complete documentation of Scikit-learn <em>CountVectorizer</em> can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)."],"metadata":{"id":"IJIKCMIRg6Dc"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer"],"metadata":{"id":"-zuoPS52gxGS","executionInfo":{"status":"ok","timestamp":1697464634122,"user_tz":-330,"elapsed":472,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["vectorizer = CountVectorizer(lowercase=True,\n","                             tokenizer=None,\n","                             token_pattern=r'(?u)\\b\\w\\w+\\b',\n","                             stop_words=None,\n","                             ngram_range=(1, 1),\n","                             vocabulary=None,\n","                             binary=False,\n","                             max_df=1.0,\n","                             min_df=1,\n","                             max_features=None)"],"metadata":{"id":"NfxtpTf_hEaE","executionInfo":{"status":"ok","timestamp":1697464680912,"user_tz":-330,"elapsed":4,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["corpus = [\n","    'This is the first document.',\n","    'This is the second second document.',\n","    'And the third one.',\n","    'Is this the first document?',\n","]\n","X = vectorizer.fit_transform(corpus)"],"metadata":{"id":"Yay8hnP2hO2d","executionInfo":{"status":"ok","timestamp":1697464685032,"user_tz":-330,"elapsed":4,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["vectorizer.get_feature_names_out()"],"metadata":{"id":"yF0dxojlhma7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697464696773,"user_tz":-330,"elapsed":432,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"0228f783-1c78-4d7f-b3bd-0f4536bf6bd2"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n","       'this'], dtype=object)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["X.toarray()"],"metadata":{"id":"8O88SHJ6hnnu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697464693158,"user_tz":-330,"elapsed":503,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"eff65844-ce05-4913-e16c-188c52c01da8"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n","       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n","       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n","       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["The converse mapping from feature name to column index is stored in the vocabulary_ attribute of the vectorizer:"],"metadata":{"id":"JpNDO4gyh0CK"}},{"cell_type":"code","source":["vectorizer.vocabulary_.get('document')"],"metadata":{"id":"syiLP3Vuh0s_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697464721387,"user_tz":-330,"elapsed":535,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"3d135c3c-d7dc-4e39-e071-93299327b31c"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["Hence words that were not seen in the training corpus will be completely ignored in future calls to the transform method:"],"metadata":{"id":"3vsfQbftiDY_"}},{"cell_type":"code","source":["vectorizer.transform(['Something completely new.']).toarray()"],"metadata":{"id":"o6kgWpfZiBnk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697464732170,"user_tz":-330,"elapsed":469,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"6ae36baf-43c6-4bf1-e943-621239e47fa6"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 0, 0, 0]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["### Bigrams"],"metadata":{"id":"NHzpna-uiQAS"}},{"cell_type":"code","source":["bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),\n","                                    token_pattern=r'\\b\\w+\\b',\n","                                    min_df=1)"],"metadata":{"id":"l_nR8X6OiR5x","executionInfo":{"status":"ok","timestamp":1697464903629,"user_tz":-330,"elapsed":4,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["X_2 = bigram_vectorizer.fit_transform(corpus).toarray()"],"metadata":{"id":"R72mmmSTiZRT","executionInfo":{"status":"ok","timestamp":1697464907164,"user_tz":-330,"elapsed":4,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["X_2"],"metadata":{"id":"SeqIJJE6ib_Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697464796645,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"c9d72672-c955-4daf-e4e6-3fedf2e00ebc"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n","       [0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0],\n","       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n","       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1]])"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["bigram_vectorizer.get_feature_names_out()"],"metadata":{"id":"Ll9ODLVeM6el","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697464800907,"user_tz":-330,"elapsed":718,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"b0dce341-4306-4330-c08e-4dfb71b6eb8e"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['and', 'and the', 'document', 'first', 'first document', 'is',\n","       'is the', 'is this', 'one', 'second', 'second document',\n","       'second second', 'the', 'the first', 'the second', 'the third',\n","       'third', 'third one', 'this', 'this is', 'this the'], dtype=object)"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","source":["## Tf–idf term weighting\n","Tf-idf (Term frequency - inverse document frequency) is measure of importance of a word in a document amoung a set of documents. Tf-idf scores provides an alternative to bag-of-words features. You can refer to [this article](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to know more about Tf-idf scoring. Scikit-learn provides the class <em>sklearn.feature_extraction.text. TfidfVectorizer</em> to convert a corpus of raw text into the Tf-idf feature representation. The complete documentation of the same can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)."],"metadata":{"id":"zZrGcYDAoF_M"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(corpus)"],"metadata":{"id":"XIra7JsMoVs-","executionInfo":{"status":"ok","timestamp":1697465299902,"user_tz":-330,"elapsed":446,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["X.toarray()"],"metadata":{"id":"YPZT4AvsPiV6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465309937,"user_tz":-330,"elapsed":455,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"f5a15b0a-345b-4bee-f5b3-e2ec8449fc50"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n","        0.        , 0.35872874, 0.        , 0.43877674],\n","       [0.        , 0.27230147, 0.        , 0.27230147, 0.        ,\n","        0.85322574, 0.22262429, 0.        , 0.27230147],\n","       [0.55280532, 0.        , 0.        , 0.        , 0.55280532,\n","        0.        , 0.28847675, 0.55280532, 0.        ],\n","       [0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n","        0.        , 0.35872874, 0.        , 0.43877674]])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["vectorizer.get_feature_names_out()"],"metadata":{"id":"TMCZQycIP4WW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465329420,"user_tz":-330,"elapsed":6,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"54e33231-61ad-4343-96f8-dcefae577ad3"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n","       'this'], dtype=object)"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["## A Complete Example of Feature Extraction from Textual Data\n","The following code snippets are based on the code given [here](https://scikit-learn.org/stable/datasets/real_world.html)."],"metadata":{"id":"IcorBuTcpywN"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups\n","newsgroups_train = fetch_20newsgroups(subset='train')"],"metadata":{"id":"bDwOUV4Ep2uE","executionInfo":{"status":"ok","timestamp":1697465393626,"user_tz":-330,"elapsed":7952,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["from pprint import pprint\n","pprint(list(newsgroups_train.target_names))"],"metadata":{"id":"oXv_-CMHqBrl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465414617,"user_tz":-330,"elapsed":440,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"b41a2c3d-a7d3-4448-e36b-c9b6381dbbdc"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["['alt.atheism',\n"," 'comp.graphics',\n"," 'comp.os.ms-windows.misc',\n"," 'comp.sys.ibm.pc.hardware',\n"," 'comp.sys.mac.hardware',\n"," 'comp.windows.x',\n"," 'misc.forsale',\n"," 'rec.autos',\n"," 'rec.motorcycles',\n"," 'rec.sport.baseball',\n"," 'rec.sport.hockey',\n"," 'sci.crypt',\n"," 'sci.electronics',\n"," 'sci.med',\n"," 'sci.space',\n"," 'soc.religion.christian',\n"," 'talk.politics.guns',\n"," 'talk.politics.mideast',\n"," 'talk.politics.misc',\n"," 'talk.religion.misc']\n"]}]},{"cell_type":"code","source":["print(newsgroups_train.filenames.shape)\n","print(newsgroups_train.target.shape)\n","print(newsgroups_train.target[:10])"],"metadata":{"id":"w77Yhn92qRdK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465435982,"user_tz":-330,"elapsed":469,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"47f6257d-73ea-44bf-d095-6902889826b7"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["(11314,)\n","(11314,)\n","[ 7  4  4  1 14 16 13  3  2  4]\n"]}]},{"cell_type":"code","source":["cats = ['alt.atheism', 'sci.space']\n","newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n","\n","print(list(newsgroups_train.target_names))\n","print(newsgroups_train.filenames.shape)\n","print(newsgroups_train.target.shape)\n","print(newsgroups_train.target[:10])"],"metadata":{"id":"JxYnIS8TqeDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465482566,"user_tz":-330,"elapsed":459,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"4ab6581f-5314-4dc3-f213-9505cc3e715b"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["['alt.atheism', 'sci.space']\n","(1073,)\n","(1073,)\n","[0 1 1 1 0 1 1 0 0 0]\n"]}]},{"cell_type":"markdown","source":["### Converting the texts into vectors"],"metadata":{"id":"P7G94JQbqppC"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","categories = ['alt.atheism', 'talk.religion.misc',\n","              'comp.graphics', 'sci.space']\n","newsgroups_train = fetch_20newsgroups(subset='train',\n","                                      categories=categories)\n","vectorizer = TfidfVectorizer()\n","vectors = vectorizer.fit_transform(newsgroups_train.data)\n","print(vectors.shape)"],"metadata":{"id":"MfTk0wA1qugn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465542465,"user_tz":-330,"elapsed":1343,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"a6eb40ed-12f8-46c2-d3cf-4b39540231e9"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["(2034, 34118)\n"]}]},{"cell_type":"code","source":["vectors.nnz / float(vectors.shape[0])"],"metadata":{"id":"RFtma4f5rBA7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465578439,"user_tz":-330,"elapsed":439,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"f2584089-82bf-448d-a742-d183ce4e5a44"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["159.0132743362832"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["###  Vectorizing the test data"],"metadata":{"id":"IlAV33ALrZZy"}},{"cell_type":"code","source":["newsgroups_test = fetch_20newsgroups(subset='test',\n","                                     categories=categories)\n","vectors_test = vectorizer.transform(newsgroups_test.data)"],"metadata":{"id":"b_rgW5ci3NNE","executionInfo":{"status":"ok","timestamp":1697465606294,"user_tz":-330,"elapsed":1897,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":["### Training a Logistic Regression Classifier"],"metadata":{"id":"saxTe-8c3WJA"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn import metrics\n","\n","clf = LogisticRegression(penalty='none')\n","clf.fit(vectors, newsgroups_train.target)\n","\n","pred = clf.predict(vectors_test)\n","metrics.f1_score(newsgroups_test.target, pred, average='macro')"],"metadata":{"id":"A_43C5xmrBog","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465618586,"user_tz":-330,"elapsed":1188,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"aefff9d4-e072-4617-f5fa-e5ce99a718e1"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["0.877168967755968"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["### Viewing the most informative features"],"metadata":{"id":"l8-74AwPrvlZ"}},{"cell_type":"code","source":["import numpy as np\n","def show_top10(classifier, vectorizer, categories):\n","    feature_names = vectorizer.get_feature_names_out()\n","    for i, category in enumerate(categories):\n","        top10 = np.argsort(np.abs(classifier.coef_[i]))[-10:]\n","        print(\"%s:\\t\\t%s\" % (category, \" \".join(feature_names[top10])))\n","show_top10(clf, vectorizer, newsgroups_train.target_names)"],"metadata":{"id":"xTKHHFHxr0_N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697465653136,"user_tz":-330,"elapsed":490,"user":{"displayName":"Suvadeep Hajra","userId":"06635352307807040625"}},"outputId":"1083d7ff-f9c4-435d-d9bb-67c2858158ab"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["alt.atheism:\t\tis tek islamic space edu atheism caltech god atheists keith\n","comp.graphics:\t\tfile polygon tiff files 3d god space points image graphics\n","sci.space:\t\tlaunch toronto pat orbit god alaska moon henry nasa space\n","talk.religion.misc:\t\tthat buffalo who jesus beast objective morality space christian god\n"]}]}]}